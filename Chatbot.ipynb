{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import nltk\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, GlobalMaxPooling1D, Flatten\n",
    "#from keras.layers.embeddings import Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting content.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile content.json\n",
    "{\"intents\": [\n",
    "        {\n",
    "        \"tag\": \"greeting\",\n",
    "            \"input\": \n",
    "                [\n",
    "                    \"hello\", \n",
    "                    \"hi there\", \n",
    "                    \"nice to meet you\", \n",
    "                    \"hi, is this is the pirate's organization\", \n",
    "                    \"any pirates here?\", \n",
    "                    \"hi\", \n",
    "                    \"hey there\", \n",
    "                    \"hey\"\n",
    "                ],\n",
    "            \"responses\": \n",
    "                [\n",
    "                    \"Hi. Welcome to the world's largest pirate organization - The Strawhats\", \n",
    "                    \"Hey yo, do you need help ?\", \n",
    "                    \"welcome aboard, how may I help you ?\", \n",
    "                    \"ahoy!!\", \n",
    "                    \"Hi random person, what do'ya want ?\", \n",
    "                    \"Hello my friend, How can I help you?\",\n",
    "                    \"Ha, Glad you showed up. How are you ?\"\n",
    "                ]\n",
    "        },\n",
    "        {\"tag\": \"goodbye\",\n",
    "            \"input\": \n",
    "                 [\n",
    "                    \"Thank you\", \n",
    "                    \"Thanks\", \n",
    "                    \"Thanks for the info\", \n",
    "                    \"bye\",\n",
    "                    \"bye bro\", \n",
    "                    \"adios\", \n",
    "                    \"okay bye\", \n",
    "                    \"goodbye\", \n",
    "                    \"see you later\", \n",
    "                    \"i will catch you later\"\n",
    "                ],\n",
    "            \"responses\": \n",
    "                 [\n",
    "                    \"Okay, Bye\", \n",
    "                    \"Have a nice day\", \n",
    "                    \"Adios\", \n",
    "                    \"Goodbye\", \n",
    "                    \"see you later\", \n",
    "                    \"nice conversation. bye\", \n",
    "                    \"okay. Have a nice day\"\n",
    "                ]\n",
    "        },\n",
    "        {\"tag\": \"howami\",\n",
    "            \"input\": \n",
    "                 [\n",
    "                    \"how are you ?\", \n",
    "                     \"I am fine\"\n",
    "                 ],\n",
    "            \"responses\": \n",
    "                 [\n",
    "                     \"Yeah, am fine\", \"Everything's going on well\", \n",
    "                     \"Doing good. Thanks you are my best friend\", \n",
    "                     \"Things are Great\", \n",
    "                     \"Yeah Fine, nothing much going on in my life\", \n",
    "                     \"I am Great , wanna join the pirate's organization?\", \n",
    "                     \"Everything's great.\", \n",
    "                     \"I am doing good. Life is boring. need to go on an adventure\", \n",
    "                     \"how are you ?\", \n",
    "                     \"are you fine?\", \n",
    "                     \"how are things going on ?\", \n",
    "                     \"everything going on okay?\", \n",
    "                     \"how's everything going?\"\n",
    "                ]\n",
    "        },\n",
    "        {\"tag\": \"whoareyou\",\n",
    "             \"input\":\n",
    "                 [\n",
    "                     \"who are you ?\", \n",
    "                     \"what are you :\",\n",
    "                     \"what is your name \", \n",
    "                     \"are you a chatbot ?\", \n",
    "                     \"what can I call you ?\", \n",
    "                     \"your name\", \n",
    "                     \"are you a bot p\"\n",
    "                 ],\n",
    "             \"responses\": \n",
    "                 [\n",
    "                     \"I am a The Great Pirate Bot ,you can call me Going Merry\",\n",
    "                     \"I am Going Merry and you could ask me questions about our organization\", \n",
    "                     \"Going Merry at your service\", \n",
    "                     \"My name is Going Merry and yes, I am the G.O.A.T\", \n",
    "                     \"You can call me TechBot and I am here to Help you\", \n",
    "                     \"My name is Going Merry and I am here to answer your questions regarding our organization. go ahead and shoot\"\n",
    "                 ]\n",
    "        },\n",
    "        {\"tag\": \"whereareyou\",\n",
    "             \"input\":\n",
    "                 [\n",
    "                     \"where are you from ?\", \n",
    "                     \"which country are you from ?\", \n",
    "                     \"where do you live ?\", \n",
    "                     \"where are you ?\", \n",
    "                     \"where do you live in?\"\n",
    "                 ],\n",
    "             \"responses\": \n",
    "                [\n",
    "                     \"I Live in the East Blue\", \n",
    "                     \"I am setting sail to the grand line\",\n",
    "                     \"I live in East Blue. Pretty sure you wouldn't have heard about that\", \n",
    "                     \"East Blue. That's where I live\"\n",
    "                ]\n",
    "        },\n",
    "        {\n",
    "        \"tag\": \"join\",\n",
    "            \"input\": \n",
    "                [\n",
    "                    \"how to get recruited ?\", \n",
    "                    \"how to join ?\", \n",
    "                    \"how do i get recruited ?\", \n",
    "                    \"How to join the strawhats ?\", \n",
    "                    \"how do I join the straw hats ?\"\n",
    "                ],\n",
    "            \"responses\": \n",
    "                [\n",
    "                    \"you need to contact the nearest straw hats center once you have completed the pre-requisites\",\n",
    "                    \"contact the closest straw hat center from your location\", \n",
    "                    \"well. there are some pre-requisite and after you complete them, find the straw hat centers\"\n",
    "                ]\n",
    "        },\n",
    "        {\n",
    "        \"tag\": \"whereisthecenter\",\n",
    "            \"input\": \n",
    "                [\n",
    "                    \"where is the straw hat center located ?\", \n",
    "                    \"location of the straw hat center ?\", \n",
    "                    \"strawhat center's location?\"\n",
    "                ],\n",
    "            \"responses\": \n",
    "                [\n",
    "                    \"That's up to you. use your skills\", \n",
    "                    \"They are present all over the city you live in. Find them on your own. I can't give any more information\", \n",
    "                    \"there are a lot of straw hat centers in the city you are in. find them\"\n",
    "                ]\n",
    "        },\n",
    "        {\n",
    "        \"tag\": \"prerequisites\",\n",
    "            \"input\": \n",
    "                [\n",
    "                    \"what are the job requirements ?\", \n",
    "                    \"what are the pre requisites ?\", \n",
    "                    \"what are the pre-requisites ?\", \n",
    "                    \"tell me about the pre-requisites\"\n",
    "                ],\n",
    "            \"responses\": \n",
    "                [\n",
    "                    \"you gotta master the art of swordfight or master Cooking and become a furious cook or you have to be the best navigator in the entire wor.ld, a swordsman, a medical reindeer, taekwando Cook, master navigator, simple minded monkey, highly intelligent strategist\"\n",
    "                ]\n",
    "        }\n",
    "   ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the dataset\n",
    "with open('content.json') as content:\n",
    "    data1 = json.load(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting all the data to lists\n",
    "tags = []\n",
    "inputs = []\n",
    "responses={}\n",
    "for intent in data1['intents']:\n",
    "    responses[intent['tag']]=intent['responses']\n",
    "    for lines in intent['input']:\n",
    "        inputs.append(lines)\n",
    "        tags.append(intent['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting to dataframe\n",
    "data = pd.DataFrame({\"inputs\": inputs,\n",
    "                      \"tags\":tags})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hello</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hi there</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nice to meet you</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hi, is this is the pirate's organization</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>any pirates here?</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hi</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hey there</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hey</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Thank you</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Thanks</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Thanks for the info</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bye</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bye bro</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>adios</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>okay bye</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>goodbye</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>see you later</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>i will catch you later</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>how are you ?</td>\n",
       "      <td>howami</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>I am fine</td>\n",
       "      <td>howami</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>who are you ?</td>\n",
       "      <td>whoareyou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>what are you :</td>\n",
       "      <td>whoareyou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>what is your name</td>\n",
       "      <td>whoareyou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>are you a chatbot ?</td>\n",
       "      <td>whoareyou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>what can I call you ?</td>\n",
       "      <td>whoareyou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>your name</td>\n",
       "      <td>whoareyou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>are you a bot p</td>\n",
       "      <td>whoareyou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>where are you from ?</td>\n",
       "      <td>whereareyou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>which country are you from ?</td>\n",
       "      <td>whereareyou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>where do you live ?</td>\n",
       "      <td>whereareyou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>where are you ?</td>\n",
       "      <td>whereareyou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>where do you live in?</td>\n",
       "      <td>whereareyou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>how to get recruited ?</td>\n",
       "      <td>join</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>how to join ?</td>\n",
       "      <td>join</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>how do i get recruited ?</td>\n",
       "      <td>join</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>How to join the strawhats ?</td>\n",
       "      <td>join</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>how do I join the straw hats ?</td>\n",
       "      <td>join</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>where is the straw hat center located ?</td>\n",
       "      <td>whereisthecenter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>location of the straw hat center ?</td>\n",
       "      <td>whereisthecenter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>strawhat center's location?</td>\n",
       "      <td>whereisthecenter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>what are the job requirements ?</td>\n",
       "      <td>prerequisites</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>what are the pre requisites ?</td>\n",
       "      <td>prerequisites</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>what are the pre-requisites ?</td>\n",
       "      <td>prerequisites</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>tell me about the pre-requisites</td>\n",
       "      <td>prerequisites</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      inputs              tags\n",
       "0                                      hello          greeting\n",
       "1                                   hi there          greeting\n",
       "2                           nice to meet you          greeting\n",
       "3   hi, is this is the pirate's organization          greeting\n",
       "4                          any pirates here?          greeting\n",
       "5                                         hi          greeting\n",
       "6                                  hey there          greeting\n",
       "7                                        hey          greeting\n",
       "8                                  Thank you           goodbye\n",
       "9                                     Thanks           goodbye\n",
       "10                       Thanks for the info           goodbye\n",
       "11                                       bye           goodbye\n",
       "12                                   bye bro           goodbye\n",
       "13                                     adios           goodbye\n",
       "14                                  okay bye           goodbye\n",
       "15                                   goodbye           goodbye\n",
       "16                             see you later           goodbye\n",
       "17                    i will catch you later           goodbye\n",
       "18                             how are you ?            howami\n",
       "19                                 I am fine            howami\n",
       "20                             who are you ?         whoareyou\n",
       "21                            what are you :         whoareyou\n",
       "22                        what is your name          whoareyou\n",
       "23                       are you a chatbot ?         whoareyou\n",
       "24                     what can I call you ?         whoareyou\n",
       "25                                 your name         whoareyou\n",
       "26                           are you a bot p         whoareyou\n",
       "27                      where are you from ?       whereareyou\n",
       "28              which country are you from ?       whereareyou\n",
       "29                       where do you live ?       whereareyou\n",
       "30                           where are you ?       whereareyou\n",
       "31                     where do you live in?       whereareyou\n",
       "32                    how to get recruited ?              join\n",
       "33                             how to join ?              join\n",
       "34                  how do i get recruited ?              join\n",
       "35               How to join the strawhats ?              join\n",
       "36            how do I join the straw hats ?              join\n",
       "37   where is the straw hat center located ?  whereisthecenter\n",
       "38        location of the straw hat center ?  whereisthecenter\n",
       "39               strawhat center's location?  whereisthecenter\n",
       "40           what are the job requirements ?     prerequisites\n",
       "41             what are the pre requisites ?     prerequisites\n",
       "42             what are the pre-requisites ?     prerequisites\n",
       "43          tell me about the pre-requisites     prerequisites"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing the data\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hello</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hi there</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nice to meet you</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hi is this is the pirates organization</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>any pirates here</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hi</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hey there</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hey</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>thank you</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>thanks</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>thanks for the info</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bye</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bye bro</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>adios</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>okay bye</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>goodbye</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>see you later</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>i will catch you later</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>how are you</td>\n",
       "      <td>howami</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>i am fine</td>\n",
       "      <td>howami</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>who are you</td>\n",
       "      <td>whoareyou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>what are you</td>\n",
       "      <td>whoareyou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>what is your name</td>\n",
       "      <td>whoareyou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>are you a chatbot</td>\n",
       "      <td>whoareyou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>what can i call you</td>\n",
       "      <td>whoareyou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>your name</td>\n",
       "      <td>whoareyou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>are you a bot p</td>\n",
       "      <td>whoareyou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>where are you from</td>\n",
       "      <td>whereareyou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>which country are you from</td>\n",
       "      <td>whereareyou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>where do you live</td>\n",
       "      <td>whereareyou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>where are you</td>\n",
       "      <td>whereareyou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>where do you live in</td>\n",
       "      <td>whereareyou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>how to get recruited</td>\n",
       "      <td>join</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>how to join</td>\n",
       "      <td>join</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>how do i get recruited</td>\n",
       "      <td>join</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>how to join the strawhats</td>\n",
       "      <td>join</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>how do i join the straw hats</td>\n",
       "      <td>join</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>where is the straw hat center located</td>\n",
       "      <td>whereisthecenter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>location of the straw hat center</td>\n",
       "      <td>whereisthecenter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>strawhat centers location</td>\n",
       "      <td>whereisthecenter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>what are the job requirements</td>\n",
       "      <td>prerequisites</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>what are the pre requisites</td>\n",
       "      <td>prerequisites</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>what are the prerequisites</td>\n",
       "      <td>prerequisites</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>tell me about the prerequisites</td>\n",
       "      <td>prerequisites</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    inputs              tags\n",
       "0                                    hello          greeting\n",
       "1                                 hi there          greeting\n",
       "2                         nice to meet you          greeting\n",
       "3   hi is this is the pirates organization          greeting\n",
       "4                         any pirates here          greeting\n",
       "5                                       hi          greeting\n",
       "6                                hey there          greeting\n",
       "7                                      hey          greeting\n",
       "8                                thank you           goodbye\n",
       "9                                   thanks           goodbye\n",
       "10                     thanks for the info           goodbye\n",
       "11                                     bye           goodbye\n",
       "12                                 bye bro           goodbye\n",
       "13                                   adios           goodbye\n",
       "14                                okay bye           goodbye\n",
       "15                                 goodbye           goodbye\n",
       "16                           see you later           goodbye\n",
       "17                  i will catch you later           goodbye\n",
       "18                            how are you             howami\n",
       "19                               i am fine            howami\n",
       "20                            who are you          whoareyou\n",
       "21                           what are you          whoareyou\n",
       "22                      what is your name          whoareyou\n",
       "23                      are you a chatbot          whoareyou\n",
       "24                    what can i call you          whoareyou\n",
       "25                               your name         whoareyou\n",
       "26                         are you a bot p         whoareyou\n",
       "27                     where are you from        whereareyou\n",
       "28             which country are you from        whereareyou\n",
       "29                      where do you live        whereareyou\n",
       "30                          where are you        whereareyou\n",
       "31                    where do you live in       whereareyou\n",
       "32                   how to get recruited               join\n",
       "33                            how to join               join\n",
       "34                 how do i get recruited               join\n",
       "35              how to join the strawhats               join\n",
       "36           how do i join the straw hats               join\n",
       "37  where is the straw hat center located   whereisthecenter\n",
       "38       location of the straw hat center   whereisthecenter\n",
       "39               strawhat centers location  whereisthecenter\n",
       "40          what are the job requirements      prerequisites\n",
       "41            what are the pre requisites      prerequisites\n",
       "42             what are the prerequisites      prerequisites\n",
       "43         tell me about the prerequisites     prerequisites"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing puntuations\n",
    "import string\n",
    "data['inputs'] = data['inputs'].apply(lambda wrd:[ltrs.lower() for ltrs in wrd if ltrs not in string.punctuation])\n",
    "data['inputs'] = data['inputs'].apply(lambda wrd: ''.join(wrd))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize the data\n",
    "tokenizer = Tokenizer(num_words=2000)\n",
    "tokenizer.fit_on_texts(data['inputs'])\n",
    "train = tokenizer.texts_to_sequences(data['inputs'])\n",
    "#apply padding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "x_train = pad_sequences(train)\n",
    "\n",
    "#encoding the outputs\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(data['tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "input_shape = x_train.shape[1]\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique words:  71\n",
      "output length:  8\n"
     ]
    }
   ],
   "source": [
    "#define vocabulary\n",
    "vocabulary = len(tokenizer.word_index)\n",
    "print(\"number of unique words: \",vocabulary)\n",
    "output_length = le.classes_.shape[0]\n",
    "print(\"output length: \",output_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Titus Varghese\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\Titus Varghese\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "#creating the model\n",
    "i = Input(shape=(input_shape,))\n",
    "x = Embedding(vocabulary+1,10)(i)\n",
    "x = LSTM(10,return_sequences=True)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(output_length,activation=\"softmax\")(x)\n",
    "model = Model(i,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiling the model\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Titus Varghese\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/200\n",
      "44/44 [==============================] - 0s 10ms/sample - loss: 2.0841 - acc: 0.0455\n",
      "Epoch 2/200\n",
      "44/44 [==============================] - 0s 431us/sample - loss: 2.0800 - acc: 0.0682\n",
      "Epoch 3/200\n",
      "44/44 [==============================] - 0s 499us/sample - loss: 2.0762 - acc: 0.1818\n",
      "Epoch 4/200\n",
      "44/44 [==============================] - 0s 499us/sample - loss: 2.0722 - acc: 0.2500\n",
      "Epoch 5/200\n",
      "44/44 [==============================] - 0s 383us/sample - loss: 2.0687 - acc: 0.2500\n",
      "Epoch 6/200\n",
      "44/44 [==============================] - 0s 373us/sample - loss: 2.0648 - acc: 0.2500\n",
      "Epoch 7/200\n",
      "44/44 [==============================] - 0s 363us/sample - loss: 2.0611 - acc: 0.2500\n",
      "Epoch 8/200\n",
      "44/44 [==============================] - 0s 340us/sample - loss: 2.0573 - acc: 0.2955\n",
      "Epoch 9/200\n",
      "44/44 [==============================] - 0s 362us/sample - loss: 2.0536 - acc: 0.2727\n",
      "Epoch 10/200\n",
      "44/44 [==============================] - 0s 363us/sample - loss: 2.0490 - acc: 0.2727\n",
      "Epoch 11/200\n",
      "44/44 [==============================] - 0s 363us/sample - loss: 2.0451 - acc: 0.2727\n",
      "Epoch 12/200\n",
      "44/44 [==============================] - 0s 363us/sample - loss: 2.0412 - acc: 0.2727\n",
      "Epoch 13/200\n",
      "44/44 [==============================] - 0s 363us/sample - loss: 2.0359 - acc: 0.2727\n",
      "Epoch 14/200\n",
      "44/44 [==============================] - 0s 380us/sample - loss: 2.0317 - acc: 0.2955\n",
      "Epoch 15/200\n",
      "44/44 [==============================] - 0s 363us/sample - loss: 2.0270 - acc: 0.2955\n",
      "Epoch 16/200\n",
      "44/44 [==============================] - 0s 420us/sample - loss: 2.0214 - acc: 0.2727\n",
      "Epoch 17/200\n",
      "44/44 [==============================] - 0s 340us/sample - loss: 2.0160 - acc: 0.2727\n",
      "Epoch 18/200\n",
      "44/44 [==============================] - 0s 363us/sample - loss: 2.0109 - acc: 0.2727\n",
      "Epoch 19/200\n",
      "44/44 [==============================] - 0s 353us/sample - loss: 2.0045 - acc: 0.2727\n",
      "Epoch 20/200\n",
      "44/44 [==============================] - 0s 295us/sample - loss: 1.9989 - acc: 0.2727\n",
      "Epoch 21/200\n",
      "44/44 [==============================] - 0s 295us/sample - loss: 1.9924 - acc: 0.2727\n",
      "Epoch 22/200\n",
      "44/44 [==============================] - 0s 317us/sample - loss: 1.9860 - acc: 0.2727\n",
      "Epoch 23/200\n",
      "44/44 [==============================] - 0s 291us/sample - loss: 1.9789 - acc: 0.2727\n",
      "Epoch 24/200\n",
      "44/44 [==============================] - 0s 375us/sample - loss: 1.9717 - acc: 0.2500\n",
      "Epoch 25/200\n",
      "44/44 [==============================] - 0s 333us/sample - loss: 1.9638 - acc: 0.2273\n",
      "Epoch 26/200\n",
      "44/44 [==============================] - 0s 317us/sample - loss: 1.9566 - acc: 0.2273\n",
      "Epoch 27/200\n",
      "44/44 [==============================] - 0s 317us/sample - loss: 1.9478 - acc: 0.2273\n",
      "Epoch 28/200\n",
      "44/44 [==============================] - 0s 305us/sample - loss: 1.9404 - acc: 0.2273\n",
      "Epoch 29/200\n",
      "44/44 [==============================] - 0s 295us/sample - loss: 1.9313 - acc: 0.2500\n",
      "Epoch 30/200\n",
      "44/44 [==============================] - 0s 308us/sample - loss: 1.9231 - acc: 0.2500\n",
      "Epoch 31/200\n",
      "44/44 [==============================] - 0s 310us/sample - loss: 1.9140 - acc: 0.2500\n",
      "Epoch 32/200\n",
      "44/44 [==============================] - 0s 303us/sample - loss: 1.9054 - acc: 0.2500\n",
      "Epoch 33/200\n",
      "44/44 [==============================] - 0s 305us/sample - loss: 1.8970 - acc: 0.2500\n",
      "Epoch 34/200\n",
      "44/44 [==============================] - 0s 286us/sample - loss: 1.8871 - acc: 0.2500\n",
      "Epoch 35/200\n",
      "44/44 [==============================] - 0s 295us/sample - loss: 1.8781 - acc: 0.2500\n",
      "Epoch 36/200\n",
      "44/44 [==============================] - 0s 284us/sample - loss: 1.8690 - acc: 0.2500\n",
      "Epoch 37/200\n",
      "44/44 [==============================] - 0s 295us/sample - loss: 1.8600 - acc: 0.2500\n",
      "Epoch 38/200\n",
      "44/44 [==============================] - 0s 295us/sample - loss: 1.8521 - acc: 0.2500\n",
      "Epoch 39/200\n",
      "44/44 [==============================] - 0s 295us/sample - loss: 1.8415 - acc: 0.2500\n",
      "Epoch 40/200\n",
      "44/44 [==============================] - 0s 317us/sample - loss: 1.8331 - acc: 0.2500\n",
      "Epoch 41/200\n",
      "44/44 [==============================] - 0s 318us/sample - loss: 1.8245 - acc: 0.2500\n",
      "Epoch 42/200\n",
      "44/44 [==============================] - 0s 285us/sample - loss: 1.8159 - acc: 0.2500\n",
      "Epoch 43/200\n",
      "44/44 [==============================] - 0s 295us/sample - loss: 1.8085 - acc: 0.2500\n",
      "Epoch 44/200\n",
      "44/44 [==============================] - ETA: 0s - loss: 1.8172 - acc: 0.250 - 0s 307us/sample - loss: 1.7991 - acc: 0.2500\n",
      "Epoch 45/200\n",
      "44/44 [==============================] - 0s 295us/sample - loss: 1.7897 - acc: 0.2500\n",
      "Epoch 46/200\n",
      "44/44 [==============================] - 0s 313us/sample - loss: 1.7807 - acc: 0.2500\n",
      "Epoch 47/200\n",
      "44/44 [==============================] - 0s 295us/sample - loss: 1.7715 - acc: 0.2500\n",
      "Epoch 48/200\n",
      "44/44 [==============================] - 0s 309us/sample - loss: 1.7619 - acc: 0.2500\n",
      "Epoch 49/200\n",
      "44/44 [==============================] - 0s 295us/sample - loss: 1.7517 - acc: 0.2500\n",
      "Epoch 50/200\n",
      "44/44 [==============================] - 0s 302us/sample - loss: 1.7430 - acc: 0.2500\n",
      "Epoch 51/200\n",
      "44/44 [==============================] - 0s 318us/sample - loss: 1.7320 - acc: 0.2727\n",
      "Epoch 52/200\n",
      "44/44 [==============================] - 0s 286us/sample - loss: 1.7221 - acc: 0.2955\n",
      "Epoch 53/200\n",
      "44/44 [==============================] - 0s 285us/sample - loss: 1.7106 - acc: 0.2955\n",
      "Epoch 54/200\n",
      "44/44 [==============================] - 0s 319us/sample - loss: 1.6991 - acc: 0.2955\n",
      "Epoch 55/200\n",
      "44/44 [==============================] - 0s 299us/sample - loss: 1.6882 - acc: 0.2955\n",
      "Epoch 56/200\n",
      "44/44 [==============================] - 0s 288us/sample - loss: 1.6752 - acc: 0.2955\n",
      "Epoch 57/200\n",
      "44/44 [==============================] - 0s 272us/sample - loss: 1.6626 - acc: 0.2955\n",
      "Epoch 58/200\n",
      "44/44 [==============================] - 0s 295us/sample - loss: 1.6508 - acc: 0.2955\n",
      "Epoch 59/200\n",
      "44/44 [==============================] - 0s 272us/sample - loss: 1.6380 - acc: 0.2955\n",
      "Epoch 60/200\n",
      "44/44 [==============================] - 0s 265us/sample - loss: 1.6254 - acc: 0.2955\n",
      "Epoch 61/200\n",
      "44/44 [==============================] - 0s 295us/sample - loss: 1.6133 - acc: 0.2955\n",
      "Epoch 62/200\n",
      "44/44 [==============================] - 0s 305us/sample - loss: 1.6007 - acc: 0.3182\n",
      "Epoch 63/200\n",
      "44/44 [==============================] - 0s 286us/sample - loss: 1.5876 - acc: 0.3182\n",
      "Epoch 64/200\n",
      "44/44 [==============================] - 0s 286us/sample - loss: 1.5742 - acc: 0.3409\n",
      "Epoch 65/200\n",
      "44/44 [==============================] - 0s 295us/sample - loss: 1.5607 - acc: 0.3409\n",
      "Epoch 66/200\n",
      "44/44 [==============================] - 0s 272us/sample - loss: 1.5469 - acc: 0.3409\n",
      "Epoch 67/200\n",
      "44/44 [==============================] - 0s 304us/sample - loss: 1.5328 - acc: 0.3636\n",
      "Epoch 68/200\n",
      "44/44 [==============================] - 0s 272us/sample - loss: 1.5188 - acc: 0.3636\n",
      "Epoch 69/200\n",
      "44/44 [==============================] - 0s 288us/sample - loss: 1.5038 - acc: 0.3636\n",
      "Epoch 70/200\n",
      "44/44 [==============================] - 0s 277us/sample - loss: 1.4903 - acc: 0.3636\n",
      "Epoch 71/200\n",
      "44/44 [==============================] - 0s 284us/sample - loss: 1.4757 - acc: 0.3636\n",
      "Epoch 72/200\n",
      "44/44 [==============================] - 0s 309us/sample - loss: 1.4618 - acc: 0.3636\n",
      "Epoch 73/200\n",
      "44/44 [==============================] - 0s 295us/sample - loss: 1.4484 - acc: 0.3636\n",
      "Epoch 74/200\n",
      "44/44 [==============================] - 0s 298us/sample - loss: 1.4342 - acc: 0.3636\n",
      "Epoch 75/200\n",
      "44/44 [==============================] - 0s 280us/sample - loss: 1.4189 - acc: 0.3636\n",
      "Epoch 76/200\n",
      "44/44 [==============================] - 0s 283us/sample - loss: 1.4032 - acc: 0.3864\n",
      "Epoch 77/200\n",
      "44/44 [==============================] - 0s 310us/sample - loss: 1.3890 - acc: 0.4091\n",
      "Epoch 78/200\n",
      "44/44 [==============================] - 0s 274us/sample - loss: 1.3730 - acc: 0.4091\n",
      "Epoch 79/200\n",
      "44/44 [==============================] - 0s 295us/sample - loss: 1.3574 - acc: 0.4545\n",
      "Epoch 80/200\n",
      "44/44 [==============================] - 0s 268us/sample - loss: 1.3429 - acc: 0.4773\n",
      "Epoch 81/200\n",
      "44/44 [==============================] - 0s 253us/sample - loss: 1.3279 - acc: 0.5000\n",
      "Epoch 82/200\n",
      "44/44 [==============================] - 0s 307us/sample - loss: 1.3133 - acc: 0.5000\n",
      "Epoch 83/200\n",
      "44/44 [==============================] - 0s 317us/sample - loss: 1.2983 - acc: 0.5227\n",
      "Epoch 84/200\n",
      "44/44 [==============================] - 0s 295us/sample - loss: 1.2828 - acc: 0.5682\n",
      "Epoch 85/200\n",
      "44/44 [==============================] - 0s 309us/sample - loss: 1.2674 - acc: 0.5909\n",
      "Epoch 86/200\n",
      "44/44 [==============================] - 0s 295us/sample - loss: 1.2528 - acc: 0.5909\n",
      "Epoch 87/200\n",
      "44/44 [==============================] - 0s 295us/sample - loss: 1.2375 - acc: 0.5909\n",
      "Epoch 88/200\n",
      "44/44 [==============================] - 0s 268us/sample - loss: 1.2222 - acc: 0.6136\n",
      "Epoch 89/200\n",
      "44/44 [==============================] - 0s 239us/sample - loss: 1.2069 - acc: 0.6364\n",
      "Epoch 90/200\n",
      "44/44 [==============================] - 0s 272us/sample - loss: 1.1896 - acc: 0.6364\n",
      "Epoch 91/200\n",
      "44/44 [==============================] - 0s 295us/sample - loss: 1.1745 - acc: 0.6818\n",
      "Epoch 92/200\n",
      "44/44 [==============================] - 0s 295us/sample - loss: 1.1593 - acc: 0.7045\n",
      "Epoch 93/200\n",
      "44/44 [==============================] - 0s 274us/sample - loss: 1.1429 - acc: 0.7273\n",
      "Epoch 94/200\n",
      "44/44 [==============================] - 0s 279us/sample - loss: 1.1271 - acc: 0.7273\n",
      "Epoch 95/200\n",
      "44/44 [==============================] - 0s 282us/sample - loss: 1.1114 - acc: 0.7273\n",
      "Epoch 96/200\n",
      "44/44 [==============================] - 0s 295us/sample - loss: 1.0954 - acc: 0.7500\n",
      "Epoch 97/200\n",
      "44/44 [==============================] - 0s 295us/sample - loss: 1.0795 - acc: 0.7500\n",
      "Epoch 98/200\n",
      "44/44 [==============================] - 0s 306us/sample - loss: 1.0636 - acc: 0.7727\n",
      "Epoch 99/200\n",
      "44/44 [==============================] - 0s 285us/sample - loss: 1.0477 - acc: 0.7727\n",
      "Epoch 100/200\n",
      "44/44 [==============================] - 0s 274us/sample - loss: 1.0309 - acc: 0.7727\n",
      "Epoch 101/200\n",
      "44/44 [==============================] - 0s 295us/sample - loss: 1.0152 - acc: 0.7727\n",
      "Epoch 102/200\n",
      "44/44 [==============================] - 0s 289us/sample - loss: 0.9975 - acc: 0.7955\n",
      "Epoch 103/200\n",
      "44/44 [==============================] - 0s 332us/sample - loss: 0.9803 - acc: 0.7955\n",
      "Epoch 104/200\n",
      "44/44 [==============================] - 0s 271us/sample - loss: 0.9633 - acc: 0.7955\n",
      "Epoch 105/200\n",
      "44/44 [==============================] - 0s 286us/sample - loss: 0.9461 - acc: 0.8182\n",
      "Epoch 106/200\n",
      "44/44 [==============================] - 0s 285us/sample - loss: 0.9302 - acc: 0.8182\n",
      "Epoch 107/200\n",
      "44/44 [==============================] - 0s 307us/sample - loss: 0.9135 - acc: 0.8182\n",
      "Epoch 108/200\n",
      "44/44 [==============================] - 0s 289us/sample - loss: 0.8972 - acc: 0.8409\n",
      "Epoch 109/200\n",
      "44/44 [==============================] - 0s 363us/sample - loss: 0.8805 - acc: 0.8409\n",
      "Epoch 110/200\n",
      "44/44 [==============================] - 0s 295us/sample - loss: 0.8629 - acc: 0.8409\n",
      "Epoch 111/200\n",
      "44/44 [==============================] - 0s 263us/sample - loss: 0.8450 - acc: 0.8636\n",
      "Epoch 112/200\n",
      "44/44 [==============================] - 0s 310us/sample - loss: 0.8284 - acc: 0.8864\n",
      "Epoch 113/200\n",
      "44/44 [==============================] - 0s 303us/sample - loss: 0.8109 - acc: 0.8864\n",
      "Epoch 114/200\n",
      "44/44 [==============================] - 0s 288us/sample - loss: 0.7950 - acc: 0.8864\n",
      "Epoch 115/200\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.7091 - acc: 0.906 - 0s 295us/sample - loss: 0.7788 - acc: 0.8864\n",
      "Epoch 116/200\n",
      "44/44 [==============================] - 0s 272us/sample - loss: 0.7630 - acc: 0.8864\n",
      "Epoch 117/200\n",
      "44/44 [==============================] - 0s 280us/sample - loss: 0.7459 - acc: 0.8864\n",
      "Epoch 118/200\n",
      "44/44 [==============================] - 0s 308us/sample - loss: 0.7287 - acc: 0.8864\n",
      "Epoch 119/200\n",
      "44/44 [==============================] - 0s 295us/sample - loss: 0.7132 - acc: 0.8864\n",
      "Epoch 120/200\n",
      "44/44 [==============================] - 0s 298us/sample - loss: 0.6975 - acc: 0.8864\n",
      "Epoch 121/200\n",
      "44/44 [==============================] - 0s 272us/sample - loss: 0.6798 - acc: 0.8864\n",
      "Epoch 122/200\n",
      "44/44 [==============================] - 0s 262us/sample - loss: 0.6642 - acc: 0.8864\n",
      "Epoch 123/200\n",
      "44/44 [==============================] - 0s 249us/sample - loss: 0.6492 - acc: 0.8864\n",
      "Epoch 124/200\n",
      "44/44 [==============================] - 0s 272us/sample - loss: 0.6345 - acc: 0.8864\n",
      "Epoch 125/200\n",
      "44/44 [==============================] - 0s 295us/sample - loss: 0.6194 - acc: 0.8864\n",
      "Epoch 126/200\n",
      "44/44 [==============================] - 0s 262us/sample - loss: 0.6034 - acc: 0.8864\n",
      "Epoch 127/200\n",
      "44/44 [==============================] - 0s 295us/sample - loss: 0.5895 - acc: 0.8864\n",
      "Epoch 128/200\n",
      "44/44 [==============================] - 0s 285us/sample - loss: 0.5745 - acc: 0.8864\n",
      "Epoch 129/200\n",
      "44/44 [==============================] - 0s 294us/sample - loss: 0.5613 - acc: 0.8864\n",
      "Epoch 130/200\n",
      "44/44 [==============================] - 0s 295us/sample - loss: 0.5504 - acc: 0.8864\n",
      "Epoch 131/200\n",
      "44/44 [==============================] - 0s 294us/sample - loss: 0.5403 - acc: 0.8864\n",
      "Epoch 132/200\n",
      "44/44 [==============================] - 0s 304us/sample - loss: 0.5244 - acc: 0.8864\n",
      "Epoch 133/200\n",
      "44/44 [==============================] - 0s 254us/sample - loss: 0.5112 - acc: 0.8864\n",
      "Epoch 134/200\n",
      "44/44 [==============================] - 0s 317us/sample - loss: 0.5024 - acc: 0.8864\n",
      "Epoch 135/200\n",
      "44/44 [==============================] - 0s 286us/sample - loss: 0.4908 - acc: 0.9091\n",
      "Epoch 136/200\n",
      "44/44 [==============================] - 0s 306us/sample - loss: 0.4784 - acc: 0.9091\n",
      "Epoch 137/200\n",
      "44/44 [==============================] - 0s 298us/sample - loss: 0.4656 - acc: 0.8864\n",
      "Epoch 138/200\n",
      "44/44 [==============================] - 0s 265us/sample - loss: 0.4557 - acc: 0.9091\n",
      "Epoch 139/200\n",
      "44/44 [==============================] - 0s 296us/sample - loss: 0.4474 - acc: 0.9091\n",
      "Epoch 140/200\n",
      "44/44 [==============================] - 0s 307us/sample - loss: 0.4393 - acc: 0.9091\n",
      "Epoch 141/200\n",
      "44/44 [==============================] - 0s 272us/sample - loss: 0.4282 - acc: 0.9091\n",
      "Epoch 142/200\n",
      "44/44 [==============================] - 0s 295us/sample - loss: 0.4170 - acc: 0.9091\n",
      "Epoch 143/200\n",
      "44/44 [==============================] - 0s 264us/sample - loss: 0.4104 - acc: 0.9318\n",
      "Epoch 144/200\n",
      "44/44 [==============================] - 0s 269us/sample - loss: 0.4015 - acc: 0.9318\n",
      "Epoch 145/200\n",
      "44/44 [==============================] - 0s 264us/sample - loss: 0.3930 - acc: 0.9545\n",
      "Epoch 146/200\n",
      "44/44 [==============================] - 0s 300us/sample - loss: 0.3832 - acc: 0.9545\n",
      "Epoch 147/200\n",
      "44/44 [==============================] - 0s 295us/sample - loss: 0.3758 - acc: 0.9318\n",
      "Epoch 148/200\n",
      "44/44 [==============================] - 0s 295us/sample - loss: 0.3685 - acc: 0.9091\n",
      "Epoch 149/200\n",
      "44/44 [==============================] - 0s 307us/sample - loss: 0.3619 - acc: 0.9318\n",
      "Epoch 150/200\n",
      "44/44 [==============================] - 0s 296us/sample - loss: 0.3545 - acc: 0.9318\n",
      "Epoch 151/200\n",
      "44/44 [==============================] - 0s 281us/sample - loss: 0.3472 - acc: 0.9773\n",
      "Epoch 152/200\n",
      "44/44 [==============================] - 0s 262us/sample - loss: 0.3410 - acc: 0.9773\n",
      "Epoch 153/200\n",
      "44/44 [==============================] - 0s 278us/sample - loss: 0.3364 - acc: 0.9773\n",
      "Epoch 154/200\n",
      "44/44 [==============================] - 0s 295us/sample - loss: 0.3299 - acc: 0.9773\n",
      "Epoch 155/200\n",
      "44/44 [==============================] - 0s 272us/sample - loss: 0.3225 - acc: 0.9773\n",
      "Epoch 156/200\n",
      "44/44 [==============================] - 0s 272us/sample - loss: 0.3154 - acc: 1.0000\n",
      "Epoch 157/200\n",
      "44/44 [==============================] - 0s 282us/sample - loss: 0.3083 - acc: 1.0000\n",
      "Epoch 158/200\n",
      "44/44 [==============================] - 0s 303us/sample - loss: 0.3020 - acc: 1.0000\n",
      "Epoch 159/200\n",
      "44/44 [==============================] - 0s 289us/sample - loss: 0.2972 - acc: 1.0000\n",
      "Epoch 160/200\n",
      "44/44 [==============================] - 0s 299us/sample - loss: 0.2911 - acc: 1.0000\n",
      "Epoch 161/200\n",
      "44/44 [==============================] - 0s 294us/sample - loss: 0.2855 - acc: 1.0000\n",
      "Epoch 162/200\n",
      "44/44 [==============================] - 0s 290us/sample - loss: 0.2807 - acc: 1.0000\n",
      "Epoch 163/200\n",
      "44/44 [==============================] - 0s 284us/sample - loss: 0.2754 - acc: 1.0000\n",
      "Epoch 164/200\n",
      "44/44 [==============================] - 0s 311us/sample - loss: 0.2705 - acc: 1.0000\n",
      "Epoch 165/200\n",
      "44/44 [==============================] - 0s 312us/sample - loss: 0.2658 - acc: 1.0000\n",
      "Epoch 166/200\n",
      "44/44 [==============================] - 0s 272us/sample - loss: 0.2605 - acc: 1.0000\n",
      "Epoch 167/200\n",
      "44/44 [==============================] - 0s 298us/sample - loss: 0.2557 - acc: 1.0000\n",
      "Epoch 168/200\n",
      "44/44 [==============================] - 0s 305us/sample - loss: 0.2518 - acc: 1.0000\n",
      "Epoch 169/200\n",
      "44/44 [==============================] - 0s 320us/sample - loss: 0.2490 - acc: 1.0000\n",
      "Epoch 170/200\n",
      "44/44 [==============================] - 0s 266us/sample - loss: 0.2448 - acc: 1.0000\n",
      "Epoch 171/200\n",
      "44/44 [==============================] - 0s 314us/sample - loss: 0.2400 - acc: 1.0000\n",
      "Epoch 172/200\n",
      "44/44 [==============================] - 0s 307us/sample - loss: 0.2368 - acc: 1.0000\n",
      "Epoch 173/200\n",
      "44/44 [==============================] - 0s 295us/sample - loss: 0.2342 - acc: 1.0000\n",
      "Epoch 174/200\n",
      "44/44 [==============================] - 0s 317us/sample - loss: 0.2319 - acc: 1.0000\n",
      "Epoch 175/200\n",
      "44/44 [==============================] - 0s 340us/sample - loss: 0.2260 - acc: 1.0000\n",
      "Epoch 176/200\n",
      "44/44 [==============================] - 0s 320us/sample - loss: 0.2206 - acc: 1.0000\n",
      "Epoch 177/200\n",
      "44/44 [==============================] - 0s 280us/sample - loss: 0.2183 - acc: 1.0000\n",
      "Epoch 178/200\n",
      "44/44 [==============================] - 0s 308us/sample - loss: 0.2181 - acc: 1.0000\n",
      "Epoch 179/200\n",
      "44/44 [==============================] - 0s 345us/sample - loss: 0.2182 - acc: 1.0000\n",
      "Epoch 180/200\n",
      "44/44 [==============================] - 0s 285us/sample - loss: 0.2119 - acc: 1.0000\n",
      "Epoch 181/200\n",
      "44/44 [==============================] - 0s 272us/sample - loss: 0.2051 - acc: 1.0000\n",
      "Epoch 182/200\n",
      "44/44 [==============================] - 0s 310us/sample - loss: 0.2062 - acc: 1.0000\n",
      "Epoch 183/200\n",
      "44/44 [==============================] - 0s 307us/sample - loss: 0.2040 - acc: 1.0000\n",
      "Epoch 184/200\n",
      "44/44 [==============================] - 0s 272us/sample - loss: 0.1985 - acc: 1.0000\n",
      "Epoch 185/200\n",
      "44/44 [==============================] - 0s 272us/sample - loss: 0.1939 - acc: 1.0000\n",
      "Epoch 186/200\n",
      "44/44 [==============================] - 0s 272us/sample - loss: 0.1925 - acc: 1.0000\n",
      "Epoch 187/200\n",
      "44/44 [==============================] - 0s 289us/sample - loss: 0.1920 - acc: 1.0000\n",
      "Epoch 188/200\n",
      "44/44 [==============================] - 0s 295us/sample - loss: 0.1902 - acc: 1.0000\n",
      "Epoch 189/200\n",
      "44/44 [==============================] - 0s 280us/sample - loss: 0.1872 - acc: 1.0000\n",
      "Epoch 190/200\n",
      "44/44 [==============================] - 0s 277us/sample - loss: 0.1822 - acc: 1.0000\n",
      "Epoch 191/200\n",
      "44/44 [==============================] - 0s 268us/sample - loss: 0.1806 - acc: 1.0000\n",
      "Epoch 192/200\n",
      "44/44 [==============================] - 0s 250us/sample - loss: 0.1799 - acc: 1.0000\n",
      "Epoch 193/200\n",
      "44/44 [==============================] - 0s 282us/sample - loss: 0.1779 - acc: 1.0000\n",
      "Epoch 194/200\n",
      "44/44 [==============================] - 0s 308us/sample - loss: 0.1749 - acc: 1.0000\n",
      "Epoch 195/200\n",
      "44/44 [==============================] - 0s 295us/sample - loss: 0.1719 - acc: 1.0000\n",
      "Epoch 196/200\n",
      "44/44 [==============================] - 0s 269us/sample - loss: 0.1693 - acc: 1.0000\n",
      "Epoch 197/200\n",
      "44/44 [==============================] - 0s 298us/sample - loss: 0.1679 - acc: 1.0000\n",
      "Epoch 198/200\n",
      "44/44 [==============================] - 0s 283us/sample - loss: 0.1652 - acc: 1.0000\n",
      "Epoch 199/200\n",
      "44/44 [==============================] - 0s 329us/sample - loss: 0.1629 - acc: 1.0000\n",
      "Epoch 200/200\n",
      "44/44 [==============================] - 0s 307us/sample - loss: 0.1609 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "#training the model\n",
    "train = model.fit(x_train,y_train,epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x29e94f08f88>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting model accuracy\n",
    "plt.plot(train.history['acc'],label='training set accuracy')\n",
    "plt.plot(train.history['loss'],label='training set loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You: hi\n",
      "Going Merry:  ahoy!!\n",
      "You: what is your name?\n",
      "Going Merry:  My name is Going Merry and yes, I am the G.O.A.T\n",
      "You: how do I join ?\n",
      "Going Merry:  you need to contact the nearest straw hats center once you have completed the pre-requisites\n",
      "You: strawhats center location?\n",
      "Going Merry:  Things are Great\n",
      "You: straw hats center location\n",
      "Going Merry:  well. there are some pre-requisite and after you complete them, find the straw hat centers\n",
      "You: strawhat centers location\t\n",
      "Going Merry:  They are present all over the city you live in. Find them on your own. I can't give any more information\n",
      "You: what are the prerequisites\t\n",
      "Going Merry:  you gotta master the art of swordfight or master Cooking and become a furious cook or you have to be the best navigator in the entire wor.ld, a swordsman, a medical reindeer, taekwando Cook, master navigator, simple minded monkey, highly intelligent strategist\n",
      "You: where do you live\twhereareyou 30\twhere are you\twhereareyou 31\twhere do you live in\twhereareyou 32\thow to get recruited\tjoin 33\thow to join\tjoin 34\thow do i get recruited\tjoin 35\thow to join the strawhats\tjoin 36\thow do i join the straw hats\tjoin 37\twhere is the straw hat center located\twhereisthecenter 38\tlocation of the straw hat center\twhereisthecenter 39\tstrawhat centers location\twhereisthecenter 40\twhat are the job requirements\tprerequisites 41\twhat are the pre requisites\tprerequisites 42\twhat are the prerequisites\tprerequisites 43\ttell me about the prerequisites\tprerequisites #tokenize the data tokenizer = Tokenizer(num_words=2000) tokenizer.fit_on_texts(data['inputs']) train = tokenizer.texts_to_sequences(data['inputs']) #apply padding from tensorflow.keras.preprocessing.sequence import pad_sequences x_train = pad_sequences(train) ​ #encoding the outputs from sklearn.preprocessing import LabelEncoder le = LabelEncoder() y_train = le.fit_transform(data['tags']) input_shape = x_train.shape[1] print(input_shape) 7 #define vocabulary vocabulary = len(tokenizer.word_index) print(\"number of unique words: \",vocabulary) output_length = le.classes_.shape[0] print(\"output length: \",output_length) number of unique words:  71 output length:  8 #creating the model i = Input(shape=(input_shape,)) x = Embedding(vocabulary+1,10)(i) x = LSTM(10,return_sequences=True)(x) x = Flatten()(x) x = Dense(output_length,activation=\"softmax\")(x) model = Model(i,x) WARNING:tensorflow:From C:\\Users\\Titus Varghese\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version. Instructions for updating: Call initializer instance with the dtype argument instead of passing it to the constructor WARNING:tensorflow:From C:\\Users\\Titus Varghese\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version. Instructions for updating: Call initializer instance with the dtype argument instead of passing it to the constructor #compiling the model model.compile(loss=\"sparse_categorical_crossentropy\",optimizer='adam',metrics=['accuracy']) #training the model train = model.fit(x_train,y_train,epochs=200) WARNING:tensorflow:From C:\\Users\\Titus Varghese\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version. Instructions for updating: Use tf.where in 2.0, which has the same broadcast rule as np.where Epoch 1/200 44/44 [==============================] - 0s 10ms/sample - loss: 2.0841 - acc: 0.0455 Epoch 2/200 44/44 [==============================] - 0s 431us/sample - loss: 2.0800 - acc: 0.0682 Epoch 3/200 44/44 [==============================] - 0s 499us/sample - loss: 2.0762 - acc: 0.1818 Epoch 4/200 44/44 [==============================] - 0s 499us/sample - loss: 2.0722 - acc: 0.2500 Epoch 5/200 44/44 [==============================] - 0s 383us/sample - loss: 2.0687 - acc: 0.2500 Epoch 6/200 44/44 [==============================] - 0s 373us/sample - loss: 2.0648 - acc: 0.2500 Epoch 7/200 44/44 [==============================] - 0s 363us/sample - loss: 2.0611 - acc: 0.2500 Epoch 8/200 44/44 [==============================] - 0s 340us/sample - loss: 2.0573 - acc: 0.2955 Epoch 9/200 44/44 [==============================] - 0s 362us/sample - loss: 2.0536 - acc: 0.2727 Epoch 10/200 44/44 [==============================] - 0s 363us/sample - loss: 2.0490 - acc: 0.2727 Epoch 11/200 44/44 [==============================] - 0s 363us/sample - loss: 2.0451 - acc: 0.2727 Epoch 12/200 44/44 [==============================] - 0s 363us/sample - loss: 2.0412 - acc: 0.2727 Epoch 13/200 44/44 [==============================] - 0s 363us/sample - loss: 2.0359 - acc: 0.2727 Epoch 14/200 44/44 [==============================] - 0s 380us/sample - loss: 2.0317 - acc: 0.2955 Epoch 15/200 44/44 [==============================] - 0s 363us/sample - loss: 2.0270 - acc: 0.2955 Epoch 16/200 44/44 [==============================] - 0s 420us/sample - loss: 2.0214 - acc: 0.2727 Epoch 17/200 44/44 [==============================] - 0s 340us/sample - loss: 2.0160 - acc: 0.2727 Epoch 18/200 44/44 [==============================] - 0s 363us/sample - loss: 2.0109 - acc: 0.2727 Epoch 19/200 44/44 [==============================] - 0s 353us/sample - loss: 2.0045 - acc: 0.2727 Epoch 20/200 44/44 [==============================] - 0s 295us/sample - loss: 1.9989 - acc: 0.2727 Epoch 21/200 44/44 [==============================] - 0s 295us/sample - loss: 1.9924 - acc: 0.2727 Epoch 22/200 44/44 [==============================] - 0s 317us/sample - loss: 1.9860 - acc: 0.2727 Epoch 23/200 44/44 [==============================] - 0s 291us/sample - loss: 1.9789 - acc: 0.2727 Epoch 24/200 44/44 [==============================] - 0s 375us/sample - loss: 1.9717 - acc: 0.2500 Epoch 25/200 44/44 [==============================] - 0s 333us/sample - loss: 1.9638 - acc: 0.2273 Epoch 26/200 44/44 [==============================] - 0s 317us/sample - loss: 1.9566 - acc: 0.2273 Epoch 27/200 44/44 [==============================] - 0s 317us/sample - loss: 1.9478 - acc: 0.2273 Epoch 28/200 44/44 [==============================] - 0s 305us/sample - loss: 1.9404 - acc: 0.2273 Epoch 29/200 44/44 [==============================] - 0s 295us/sample - loss: 1.9313 - acc: 0.2500 Epoch 30/200 44/44 [==============================] - 0s 308us/sample - loss: 1.9231 - acc: 0.2500 Epoch 31/200 44/44 [==============================] - 0s 310us/sample - loss: 1.9140 - acc: 0.2500 Epoch 32/200 44/44 [==============================] - 0s 303us/sample - loss: 1.9054 - acc: 0.2500 Epoch 33/200 44/44 [==============================] - 0s 305us/sample - loss: 1.8970 - acc: 0.2500 Epoch 34/200 44/44 [==============================] - 0s 286us/sample - loss: 1.8871 - acc: 0.2500 Epoch 35/200 44/44 [==============================] - 0s 295us/sample - loss: 1.8781 - acc: 0.2500 Epoch 36/200 44/44 [==============================] - 0s 284us/sample - loss: 1.8690 - acc: 0.2500 Epoch 37/200 44/44 [==============================] - 0s 295us/sample - loss: 1.8600 - acc: 0.2500 Epoch 38/200 44/44 [==============================] - 0s 295us/sample - loss: 1.8521 - acc: 0.2500 Epoch 39/200 44/44 [==============================] - 0s 295us/sample - loss: 1.8415 - acc: 0.2500 Epoch 40/200 44/44 [==============================] - 0s 317us/sample - loss: 1.8331 - acc: 0.2500 Epoch 41/200 44/44 [==============================] - 0s 318us/sample - loss: 1.8245 - acc: 0.2500 Epoch 42/200 44/44 [==============================] - 0s 285us/sample - loss: 1.8159 - acc: 0.2500 Epoch 43/200 44/44 [==============================] - 0s 295us/sample - loss: 1.8085 - acc: 0.2500 Epoch 44/200 44/44 [==============================] - ETA: 0s - loss: 1.8172 - acc: 0.250 - 0s 307us/sample - loss: 1.7991 - acc: 0.2500 Epoch 45/200 44/44 [==============================] - 0s 295us/sample - loss: 1.7897 - acc: 0.2500 Epoch 46/200 44/44 [==============================] - 0s 313us/sample - loss: 1.7807 - acc: 0.2500 Epoch 47/200 44/44 [==============================] - 0s 295us/sample - loss: 1.7715 - acc: 0.2500 Epoch 48/200 44/44 [==============================] - 0s 309us/sample - loss: 1.7619 - acc: 0.2500 Epoch 49/200 44/44 [==============================] - 0s 295us/sample - loss: 1.7517 - acc: 0.2500 Epoch 50/200 44/44 [==============================] - 0s 302us/sample - loss: 1.7430 - acc: 0.2500 Epoch 51/200 44/44 [==============================] - 0s 318us/sample - loss: 1.7320 - acc: 0.2727 Epoch 52/200 44/44 [==============================] - 0s 286us/sample - loss: 1.7221 - acc: 0.2955 Epoch 53/200 44/44 [==============================] - 0s 285us/sample - loss: 1.7106 - acc: 0.2955 Epoch 54/200 44/44 [==============================] - 0s 319us/sample - loss: 1.6991 - acc: 0.2955 Epoch 55/200 44/44 [==============================] - 0s 299us/sample - loss: 1.6882 - acc: 0.2955 Epoch 56/200 44/44 [==============================] - 0s 288us/sample - loss: 1.6752 - acc: 0.2955 Epoch 57/200 44/44 [==============================] - 0s 272us/sample - loss: 1.6626 - acc: 0.2955 Epoch 58/200 44/44 [==============================] - 0s 295us/sample - loss: 1.6508 - acc: 0.2955 Epoch 59/200 44/44 [==============================] - 0s 272us/sample - loss: 1.6380 - acc: 0.2955 Epoch 60/200 44/44 [==============================] - 0s 265us/sample - loss: 1.6254 - acc: 0.2955 Epoch 61/200 44/44 [==============================] - 0s 295us/sample - loss: 1.6133 - acc: 0.2955 Epoch 62/200 44/44 [==============================] - 0s 305us/sample - loss: 1.6007 - acc: 0.3182 Epoch 63/200 44/44 [==============================] - 0s 286us/sample - loss: 1.5876 - acc: 0.3182 Epoch 64/200 44/44 [==============================] - 0s 286us/sample - loss: 1.5742 - acc: 0.3409 Epoch 65/200 44/44 [==============================] - 0s 295us/sample - loss: 1.5607 - acc: 0.3409 Epoch 66/200 44/44 [==============================] - 0s 272us/sample - loss: 1.5469 - acc: 0.3409 Epoch 67/200 44/44 [==============================] - 0s 304us/sample - loss: 1.5328 - acc: 0.3636 Epoch 68/200 44/44 [==============================] - 0s 272us/sample - loss: 1.5188 - acc: 0.3636 Epoch 69/200 44/44 [==============================] - 0s 288us/sample - loss: 1.5038 - acc: 0.3636 Epoch 70/200 44/44 [==============================] - 0s 277us/sample - loss: 1.4903 - acc: 0.3636 Epoch 71/200 44/44 [==============================] - 0s 284us/sample - loss: 1.4757 - acc: 0.3636 Epoch 72/200 44/44 [==============================] - 0s 309us/sample - loss: 1.4618 - acc: 0.3636 Epoch 73/200 44/44 [==============================] - 0s 295us/sample - loss: 1.4484 - acc: 0.3636 Epoch 74/200 44/44 [==============================] - 0s 298us/sample - loss: 1.4342 - acc: 0.3636 Epoch 75/200 44/44 [==============================] - 0s 280us/sample - loss: 1.4189 - acc: 0.3636 Epoch 76/200 44/44 [==============================] - 0s 283us/sample - loss: 1.4032 - acc: 0.3864 Epoch 77/200 44/44 [==============================] - 0s 310us/sample - loss: 1.3890 - acc: 0.4091 Epoch 78/200 44/44 [==============================] - 0s 274us/sample - loss: 1.3730 - acc: 0.4091 Epoch 79/200 44/44 [==============================] - 0s 295us/sample - loss: 1.3574 - acc: 0.4545 Epoch 80/200 44/44 [==============================] - 0s 268us/sample - loss: 1.3429 - acc: 0.4773 Epoch 81/200 44/44 [==============================] - 0s 253us/sample - loss: 1.3279 - acc: 0.5000 Epoch 82/200 44/44 [==============================] - 0s 307us/sample - loss: 1.3133 - acc: 0.5000 Epoch 83/200 44/44 [==============================] - 0s 317us/sample - loss: 1.2983 - acc: 0.5227 Epoch 84/200 44/44 [==============================] - 0s 295us/sample - loss: 1.2828 - acc: 0.5682 Epoch 85/200 44/44 [==============================] - 0s 309us/sample - loss: 1.2674 - acc: 0.5909 Epoch 86/200 44/44 [==============================] - 0s 295us/sample - loss: 1.2528 - acc: 0.5909 Epoch 87/200 44/44 [==============================] - 0s 295us/sample - loss: 1.2375 - acc: 0.5909 Epoch 88/200 44/44 [==============================] - 0s 268us/sample - loss: 1.2222 - acc: 0.6136 Epoch 89/200 44/44 [==============================] - 0s 239us/sample - loss: 1.2069 - acc: 0.6364 Epoch 90/200 44/44 [==============================] - 0s 272us/sample - loss: 1.1896 - acc: 0.6364 Epoch 91/200 44/44 [==============================] - 0s 295us/sample - loss: 1.1745 - acc: 0.6818 Epoch 92/200 44/44 [==============================] - 0s 295us/sample - loss: 1.1593 - acc: 0.7045 Epoch 93/200 44/44 [==============================] - 0s 274us/sample - loss: 1.1429 - acc: 0.7273 Epoch 94/200 44/44 [==============================] - 0s 279us/sample - loss: 1.1271 - acc: 0.7273 Epoch 95/200 44/44 [==============================] - 0s 282us/sample - loss: 1.1114 - acc: 0.7273 Epoch 96/200 44/44 [==============================] - 0s 295us/sample - loss: 1.0954 - acc: 0.7500 Epoch 97/200 44/44 [==============================] - 0s 295us/sample - loss: 1.0795 - acc: 0.7500 Epoch 98/200 44/44 [==============================] - 0s 306us/sample - loss: 1.0636 - acc: 0.7727 Epoch 99/200 44/44 [==============================] - 0s 285us/sample - loss: 1.0477 - acc: 0.7727 Epoch 100/200 44/44 [==============================] - 0s 274us/sample - loss: 1.0309 - acc: 0.7727 Epoch 101/200 44/44 [==============================] - 0s 295us/sample - loss: 1.0152 - acc: 0.7727 Epoch 102/200 44/44 [==============================] - 0s 289us/sample - loss: 0.9975 - acc: 0.7955 Epoch 103/200 44/44 [==============================] - 0s 332us/sample - loss: 0.9803 - acc: 0.7955 Epoch 104/200 44/44 [==============================] - 0s 271us/sample - loss: 0.9633 - acc: 0.7955 Epoch 105/200 44/44 [==============================] - 0s 286us/sample - loss: 0.9461 - acc: 0.8182 Epoch 106/200 44/44 [==============================] - 0s 285us/sample - loss: 0.9302 - acc: 0.8182 Epoch 107/200 44/44 [==============================] - 0s 307us/sample - loss: 0.9135 - acc: 0.8182 Epoch 108/200 44/44 [==============================] - 0s 289us/sample - loss: 0.8972 - acc: 0.8409 Epoch 109/200 44/44 [==============================] - 0s 363us/sample - loss: 0.8805 - acc: 0.8409 Epoch 110/200 44/44 [==============================] - 0s 295us/sample - loss: 0.8629 - acc: 0.8409 Epoch 111/200 44/44 [==============================] - 0s 263us/sample - loss: 0.8450 - acc: 0.8636 Epoch 112/200 44/44 [==============================] - 0s 310us/sample - loss: 0.8284 - acc: 0.8864 Epoch 113/200 44/44 [==============================] - 0s 303us/sample - loss: 0.8109 - acc: 0.8864 Epoch 114/200 44/44 [==============================] - 0s 288us/sample - loss: 0.7950 - acc: 0.8864 Epoch 115/200 44/44 [==============================] - ETA: 0s - loss: 0.7091 - acc: 0.906 - 0s 295us/sample - loss: 0.7788 - acc: 0.8864 Epoch 116/200 44/44 [==============================] - 0s 272us/sample - loss: 0.7630 - acc: 0.8864 Epoch 117/200 44/44 [==============================] - 0s 280us/sample - loss: 0.7459 - acc: 0.8864 Epoch 118/200 44/44 [==============================] - 0s 308us/sample - loss: 0.7287 - acc: 0.8864 Epoch 119/200 44/44 [==============================] - 0s 295us/sample - loss: 0.7132 - acc: 0.8864 Epoch 120/200 44/44 [==============================] - 0s 298us/sample - loss: 0.6975 - acc: 0.8864 Epoch 121/200 44/44 [==============================] - 0s 272us/sample - loss: 0.6798 - acc: 0.8864 Epoch 122/200 44/44 [==============================] - 0s 262us/sample - loss: 0.6642 - acc: 0.8864 Epoch 123/200 44/44 [==============================] - 0s 249us/sample - loss: 0.6492 - acc: 0.8864 Epoch 124/200 44/44 [==============================] - 0s 272us/sample - loss: 0.6345 - acc: 0.8864 Epoch 125/200 44/44 [==============================] - 0s 295us/sample - loss: 0.6194 - acc: 0.8864 Epoch 126/200 44/44 [==============================] - 0s 262us/sample - loss: 0.6034 - acc: 0.8864 Epoch 127/200 44/44 [==============================] - 0s 295us/sample - loss: 0.5895 - acc: 0.8864 Epoch 128/200 44/44 [==============================] - 0s 285us/sample - loss: 0.5745 - acc: 0.8864 Epoch 129/200 44/44 [==============================] - 0s 294us/sample - loss: 0.5613 - acc: 0.8864 Epoch 130/200 44/44 [==============================] - 0s 295us/sample - loss: 0.5504 - acc: 0.8864 Epoch 131/200 44/44 [==============================] - 0s 294us/sample - loss: 0.5403 - acc: 0.8864 Epoch 132/200 44/44 [==============================] - 0s 304us/sample - loss: 0.5244 - acc: 0.8864 Epoch 133/200 44/44 [==============================] - 0s 254us/sample - loss: 0.5112 - acc: 0.8864 Epoch 134/200 44/44 [==============================] - 0s 317us/sample - loss: 0.5024 - acc: 0.8864 Epoch 135/200 44/44 [==============================] - 0s 286us/sample - loss: 0.4908 - acc: 0.9091 Epoch 136/200 44/44 [==============================] - 0s 306us/sample - loss: 0.4784 - acc: 0.9091 Epoch 137/200 44/44 [==============================] - 0s 298us/sample - loss: 0.4656 - acc: 0.8864 Epoch 138/200 44/44 [==============================] - 0s 265us/sample - loss: 0.4557 - acc: 0.9091 Epoch 139/200 44/44 [==============================] - 0s 296us/sample - loss: 0.4474 - acc: 0.9091 Epoch 140/200 44/44 [==============================] - 0s 307us/sample - loss: 0.4393 - acc: 0.9091 Epoch 141/200 44/44 [==============================] - 0s 272us/sample - loss: 0.4282 - acc: 0.9091 Epoch 142/200 44/44 [==============================] - 0s 295us/sample - loss: 0.4170 - acc: 0.9091 Epoch 143/200 44/44 [==============================] - 0s 264us/sample - loss: 0.4104 - acc: 0.9318 Epoch 144/200 44/44 [==============================] - 0s 269us/sample - loss: 0.4015 - acc: 0.9318 Epoch 145/200 44/44 [==============================] - 0s 264us/sample - loss: 0.3930 - acc: 0.9545 Epoch 146/200 44/44 [==============================] - 0s 300us/sample - loss: 0.3832 - acc: 0.9545 Epoch 147/200 44/44 [==============================] - 0s 295us/sample - loss: 0.3758 - acc: 0.9318 Epoch 148/200 44/44 [==============================] - 0s 295us/sample - loss: 0.3685 - acc: 0.9091 Epoch 149/200 44/44 [==============================] - 0s 307us/sample - loss: 0.3619 - acc: 0.9318 Epoch 150/200 44/44 [==============================] - 0s 296us/sample - loss: 0.3545 - acc: 0.9318 Epoch 151/200 44/44 [==============================] - 0s 281us/sample - loss: 0.3472 - acc: 0.9773 Epoch 152/200 44/44 [==============================] - 0s 262us/sample - loss: 0.3410 - acc: 0.9773 Epoch 153/200 44/44 [==============================] - 0s 278us/sample - loss: 0.3364 - acc: 0.9773 Epoch 154/200 44/44 [==============================] - 0s 295us/sample - loss: 0.3299 - acc: 0.9773 Epoch 155/200 44/44 [==============================] - 0s 272us/sample - loss: 0.3225 - acc: 0.9773 Epoch 156/200 44/44 [==============================] - 0s 272us/sample - loss: 0.3154 - acc: 1.0000 Epoch 157/200 44/44 [==============================] - 0s 282us/sample - loss: 0.3083 - acc: 1.0000 Epoch 158/200 44/44 [==============================] - 0s 303us/sample - loss: 0.3020 - acc: 1.0000 Epoch 159/200 44/44 [==============================] - 0s 289us/sample - loss: 0.2972 - acc: 1.0000 Epoch 160/200 44/44 [==============================] - 0s 299us/sample - loss: 0.2911 - acc: 1.0000 Epoch 161/200 44/44 [==============================] - 0s 294us/sample - loss: 0.2855 - acc: 1.0000 Epoch 162/200 44/44 [==============================] - 0s 290us/sample - loss: 0.2807 - acc: 1.0000 Epoch 163/200 44/44 [==============================] - 0s 284us/sample - loss: 0.2754 - acc: 1.0000 Epoch 164/200 44/44 [==============================] - 0s 311us/sample - loss: 0.2705 - acc: 1.0000 Epoch 165/200 44/44 [==============================] - 0s 312us/sample - loss: 0.2658 - acc: 1.0000 Epoch 166/200 44/44 [==============================] - 0s 272us/sample - loss: 0.2605 - acc: 1.0000 Epoch 167/200 44/44 [==============================] - 0s 298us/sample - loss: 0.2557 - acc: 1.0000 Epoch 168/200 44/44 [==============================] - 0s 305us/sample - loss: 0.2518 - acc: 1.0000 Epoch 169/200 44/44 [==============================] - 0s 320us/sample - loss: 0.2490 - acc: 1.0000 Epoch 170/200 44/44 [==============================] - 0s 266us/sample - loss: 0.2448 - acc: 1.0000 Epoch 171/200 44/44 [==============================] - 0s 314us/sample - loss: 0.2400 - acc: 1.0000 Epoch 172/200 44/44 [==============================] - 0s 307us/sample - loss: 0.2368 - acc: 1.0000 Epoch 173/200 44/44 [==============================] - 0s 295us/sample - loss: 0.2342 - acc: 1.0000 Epoch 174/200 44/44 [==============================] - 0s 317us/sample - loss: 0.2319 - acc: 1.0000 Epoch 175/200 44/44 [==============================] - 0s 340us/sample - loss: 0.2260 - acc: 1.0000 Epoch 176/200 44/44 [==============================] - 0s 320us/sample - loss: 0.2206 - acc: 1.0000 Epoch 177/200 44/44 [==============================] - 0s 280us/sample - loss: 0.2183 - acc: 1.0000 Epoch 178/200 44/44 [==============================] - 0s 308us/sample - loss: 0.2181 - acc: 1.0000 Epoch 179/200 44/44 [==============================] - 0s 345us/sample - loss: 0.2182 - acc: 1.0000 Epoch 180/200 44/44 [==============================] - 0s 285us/sample - loss: 0.2119 - acc: 1.0000 Epoch 181/200 44/44 [==============================] - 0s 272us/sample - loss: 0.2051 - acc: 1.0000 Epoch 182/200 44/44 [==============================] - 0s 310us/sample - loss: 0.2062 - acc: 1.0000 Epoch 183/200 44/44 [==============================] - 0s 307us/sample - loss: 0.2040 - acc: 1.0000 Epoch 184/200 44/44 [==============================] - 0s 272us/sample - loss: 0.1985 - acc: 1.0000 Epoch 185/200 44/44 [==============================] - 0s 272us/sample - loss: 0.1939 - acc: 1.0000 Epoch 186/200 44/44 [==============================] - 0s 272us/sample - loss: 0.1925 - acc: 1.0000 Epoch 187/200 44/44 [==============================] - 0s 289us/sample - loss: 0.1920 - acc: 1.0000 Epoch 188/200 44/44 [==============================] - 0s 295us/sample - loss: 0.1902 - acc: 1.0000 Epoch 189/200 44/44 [==============================] - 0s 280us/sample - loss: 0.1872 - acc: 1.0000 Epoch 190/200 44/44 [==============================] - 0s 277us/sample - loss: 0.1822 - acc: 1.0000 Epoch 191/200 44/44 [==============================] - 0s 268us/sample - loss: 0.1806 - acc: 1.0000 Epoch 192/200 44/44 [==============================] - 0s 250us/sample - loss: 0.1799 - acc: 1.0000 Epoch 193/200 44/44 [==============================] - 0s 282us/sample - loss: 0.1779 - acc: 1.0000 Epoch 194/200 44/44 [==============================] - 0s 308us/sample - loss: 0.1749 - acc: 1.0000 Epoch 195/200 44/44 [==============================] - 0s 295us/sample - loss: 0.1719 - acc: 1.0000 Epoch 196/200 44/44 [==============================] - 0s 269us/sample - loss: 0.1693 - acc: 1.0000 Epoch 197/200 44/44 [==============================] - 0s 298us/sample - loss: 0.1679 - acc: 1.0000 Epoch 198/200 44/44 [==============================] - 0s 283us/sample - loss: 0.1652 - acc: 1.0000 Epoch 199/200 44/44 [==============================] - 0s 329us/sample - loss: 0.1629 - acc: 1.0000 Epoch 200/200 44/44 [==============================] - 0s 307us/sample - loss: 0.1609 - acc: 1.0000 #plotting model accuracy plt.plot(train.history['acc'],label='training set accuracy') plt.plot(train.history['loss'],label='training set loss') plt.legend() <matplotlib.legend.Legend at 0x29e94f08f88>  #chatting import random import string ​ while True:     texts_p = []     prediction_input = input('You: ')     #removing punctuation and converting to lowercase     prediction_input = [letters.lower() for letters in prediction_input if letters not in string.punctuation]     prediction_input = ''.join(prediction_input)     texts_p.append(prediction_input)          #tokenizing and padding     prediction_input = tokenizer.texts_to_sequences(texts_p)     prediction_input = np.array(prediction_input).reshape(-1)     prediction_input = pad_sequences([prediction_input],input_shape) ​     #getting output from model     output = model.predict(prediction_input)     output = output.argmax() ​     #finding the right tag and predicting     response_tag = le.inverse_transform([output])[0]     print(\"Going Merry: \",random.choice(responses[response_tag]))     if response_tag == \"goodbye\":         break You: hi Going Merry:  ahoy!! You: what is your name? Going Merry:  My name is Going Merry and yes, I am the G.O.A.T You: how do I join ? Going Merry:  you need to contact the nearest straw hats center once you have completed the pre-requisites You: strawhats center location? Going Merry:  Things are Great You: straw hats center location Going Merry:  well. there are some pre-requisite and after you complete them, find the straw hat centers You: strawhat centers location\t Going Merry:  They are present all over the city you live in. Find them on your own. I can't give any more information You: what are the prerequisites\t Going Merry:  you gotta master the art of swordfight or master Cooking and become a furious cook or you have to be the best navigator in the entire wor.ld, a swordsman, a medical reindeer, taekwando Cook, master navigator, simple minded monkey, highly intelligent strategist You:  ​\n",
      "Going Merry:  you need to contact the nearest straw hats center once you have completed the pre-requisites\n",
      "You: are you a bot p\t\n",
      "Going Merry:  I am a The Great Pirate Bot ,you can call me Going Merry\n",
      "You: adios\n",
      "Going Merry:  see you later\n"
     ]
    }
   ],
   "source": [
    "#chatting\n",
    "import random\n",
    "import string\n",
    "\n",
    "while True:\n",
    "    texts_p = []\n",
    "    prediction_input = input('You: ')\n",
    "    #removing punctuation and converting to lowercase\n",
    "    prediction_input = [letters.lower() for letters in prediction_input if letters not in string.punctuation]\n",
    "    prediction_input = ''.join(prediction_input)\n",
    "    texts_p.append(prediction_input)\n",
    "    \n",
    "    #tokenizing and padding\n",
    "    prediction_input = tokenizer.texts_to_sequences(texts_p)\n",
    "    prediction_input = np.array(prediction_input).reshape(-1)\n",
    "    prediction_input = pad_sequences([prediction_input],input_shape)\n",
    "\n",
    "    #getting output from model\n",
    "    output = model.predict(prediction_input)\n",
    "    output = output.argmax()\n",
    "\n",
    "    #finding the right tag and predicting\n",
    "    response_tag = le.inverse_transform([output])[0]\n",
    "    print(\"Going Merry: \",random.choice(responses[response_tag]))\n",
    "    if response_tag == \"goodbye\":\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
